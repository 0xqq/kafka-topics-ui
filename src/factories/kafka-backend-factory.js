/**
 * Kafka-Rest-Proxy angularJS Factory
 * version 0.7-SNAPSHOT (18.Aug.2016)
 *
 * @author antonios@landoop.com
 */
angularAPP.factory('KafkaBackendFactory', function ($rootScope, $http, $log, $base64, $q, Oboe, toastFactory, env) {

function getListInfo() {
//    var url = env.KAFKA_BACKEND() + '/topics/summaries';
//    var deferred = $q.defer();
//   $http.get(url).then(
//        function success(response) {
//          var topicInfo = response.data;
//          deferred.resolve(topicInfo);
//        },
//        function failure(response) {
//          $log.error("Error in getting topics from kafka-rest : " + JSON.stringify(response));
//          deferred.reject("Error in getting topics from kafka-rest");
//        });
//
//    return deferred.promise;
data = [{"keyType":"string","valueType":"string","totalMessages":21,"replication":1,"topicName":"_confluent-controlcenter-0-MonitoringStream-ONE_WEEK-changelog","customConfig":[{"configuration":"segment.bytes","value":"134217728","defaultValue":"1 GB","documentation":"This configuration controls the segment file size for the log. Retention and cleaning is always done a file at a time so a larger segment size means fewer files but less granular control over retention."},{"configuration":"delete.retention.ms","value":"86400000","defaultValue":"86400000","documentation":"The amount of time to retain delete tombstone markers for log compacted topics. This setting also gives a bound on the time in which a consumer must complete a read if they begin from offset 0 to ensure that they get a valid snapshot of the final stage (otherwise delete tombstones may be collected before they complete their scan). Default is 24 hours"},{"configuration":"cleanup.policy","value":"compact","defaultValue":"delete","documentation":"A string that is either \"delete\" or \"compact\". This string designates the retention policy to use on old log segments. The default policy (\"delete\") will discard old segments when their retention time or size limit has been reached. The \"compact\" setting will enable log compaction on the topic."},{"configuration":"min.insync.replicas","value":"1","defaultValue":"1","documentation":"When a producer sets acks to \"all\", min.insync.replicas specifies the minimum number of replicas that must acknowledge a write for the write to be considered successful. If this minimum cannot be met, then the producer will raise an exception (either NotEnoughReplicas or NotEnoughReplicasAfterAppend). When used together, min.insync.replicas and acks allow you to enforce greater durability guarantees. A typical scenario would be to create a topic with a replication factor of 3, set min.insync.replicas to 2, and produce with acks of \"all\". This will ensure that the producer raises an exception if a majority of replicas do not receive a write."}],"partitions":1,"isControlTopic":false,"messagesPerPartition":[{"partition":0,"messages":21}]},{"keyType":"string","valueType":"json","totalMessages":35,"replication":1,"topicName":"connect-configs","partitions":1,"isControlTopic":true,"messagesPerPartition":[{"partition":0,"messages":35}]},{"keyType":"empty","valueType":"empty","totalMessages":0,"replication":1,"topicName":"_confluent-controlcenter-0-group-aggregate-topic-ONE_WEEK","customConfig":[{"configuration":"retention.ms","value":"86400000","defaultValue":"7 days","documentation":"This configuration controls the maximum time we will retain a log before we will discard old log segments to free up space if we are using the \"delete\" retention policy. This represents an SLA on how soon consumers must read their data."},{"configuration":"min.insync.replicas","value":"1","defaultValue":"1","documentation":"When a producer sets acks to \"all\", min.insync.replicas specifies the minimum number of replicas that must acknowledge a write for the write to be considered successful. If this minimum cannot be met, then the producer will raise an exception (either NotEnoughReplicas or NotEnoughReplicasAfterAppend). When used together, min.insync.replicas and acks allow you to enforce greater durability guarantees. A typical scenario would be to create a topic with a replication factor of 3, set min.insync.replicas to 2, and produce with acks of \"all\". This will ensure that the producer raises an exception if a majority of replicas do not receive a write."},{"configuration":"retention.bytes","value":"-1","defaultValue":"None","documentation":"This configuration controls the maximum size a log can grow to before we will discard old log segments to free up space if we are using the \"delete\" retention policy. By default there is no size limit only a time limit."}],"partitions":1,"isControlTopic":false,"messagesPerPartition":[{"partition":0,"messages":0}]},{"keyType":"empty","valueType":"empty","totalMessages":0,"replication":1,"topicName":"device-measurement2","partitions":1,"isControlTopic":false,"messagesPerPartition":[{"partition":0,"messages":0}]},{"keyType":"empty","valueType":"empty","totalMessages":0,"replication":1,"topicName":"tweets","partitions":1,"isControlTopic":false,"messagesPerPartition":[{"partition":0,"messages":0}]},{"keyType":"string","valueType":"string","totalMessages":21,"replication":1,"topicName":"_confluent-controlcenter-0-MonitoringStream-ONE_HOUR-changelog","customConfig":[{"configuration":"segment.bytes","value":"134217728","defaultValue":"1 GB","documentation":"This configuration controls the segment file size for the log. Retention and cleaning is always done a file at a time so a larger segment size means fewer files but less granular control over retention."},{"configuration":"delete.retention.ms","value":"86400000","defaultValue":"86400000","documentation":"The amount of time to retain delete tombstone markers for log compacted topics. This setting also gives a bound on the time in which a consumer must complete a read if they begin from offset 0 to ensure that they get a valid snapshot of the final stage (otherwise delete tombstones may be collected before they complete their scan). Default is 24 hours"},{"configuration":"cleanup.policy","value":"compact","defaultValue":"delete","documentation":"A string that is either \"delete\" or \"compact\". This string designates the retention policy to use on old log segments. The default policy (\"delete\") will discard old segments when their retention time or size limit has been reached. The \"compact\" setting will enable log compaction on the topic."},{"configuration":"min.insync.replicas","value":"1","defaultValue":"1","documentation":"When a producer sets acks to \"all\", min.insync.replicas specifies the minimum number of replicas that must acknowledge a write for the write to be considered successful. If this minimum cannot be met, then the producer will raise an exception (either NotEnoughReplicas or NotEnoughReplicasAfterAppend). When used together, min.insync.replicas and acks allow you to enforce greater durability guarantees. A typical scenario would be to create a topic with a replication factor of 3, set min.insync.replicas to 2, and produce with acks of \"all\". This will ensure that the producer raises an exception if a majority of replicas do not receive a write."}],"partitions":1,"isControlTopic":false,"messagesPerPartition":[{"partition":0,"messages":21}]},{"keyType":"","valueType":"avro","totalMessages":32347,"replication":1,"topicName":"yahoo-fx","partitions":1,"isControlTopic":false,"messagesPerPartition":[{"partition":0,"messages":32347}]},{"keyType":"empty","valueType":"empty","totalMessages":0,"replication":1,"topicName":"iot","partitions":1,"isControlTopic":false,"messagesPerPartition":[{"partition":0,"messages":0}]},{"keyType":"empty","valueType":"empty","totalMessages":0,"replication":1,"topicName":"twitter","partitions":1,"isControlTopic":false,"messagesPerPartition":[{"partition":0,"messages":0}]},{"keyType":"string","valueType":"string","totalMessages":10,"replication":1,"topicName":"_confluent-controlcenter-0-Group-FIFTEEN_SECONDS-changelog","customConfig":[{"configuration":"segment.bytes","value":"134217728","defaultValue":"1 GB","documentation":"This configuration controls the segment file size for the log. Retention and cleaning is always done a file at a time so a larger segment size means fewer files but less granular control over retention."},{"configuration":"delete.retention.ms","value":"86400000","defaultValue":"86400000","documentation":"The amount of time to retain delete tombstone markers for log compacted topics. This setting also gives a bound on the time in which a consumer must complete a read if they begin from offset 0 to ensure that they get a valid snapshot of the final stage (otherwise delete tombstones may be collected before they complete their scan). Default is 24 hours"},{"configuration":"cleanup.policy","value":"compact","defaultValue":"delete","documentation":"A string that is either \"delete\" or \"compact\". This string designates the retention policy to use on old log segments. The default policy (\"delete\") will discard old segments when their retention time or size limit has been reached. The \"compact\" setting will enable log compaction on the topic."},{"configuration":"min.insync.replicas","value":"1","defaultValue":"1","documentation":"When a producer sets acks to \"all\", min.insync.replicas specifies the minimum number of replicas that must acknowledge a write for the write to be considered successful. If this minimum cannot be met, then the producer will raise an exception (either NotEnoughReplicas or NotEnoughReplicasAfterAppend). When used together, min.insync.replicas and acks allow you to enforce greater durability guarantees. A typical scenario would be to create a topic with a replication factor of 3, set min.insync.replicas to 2, and produce with acks of \"all\". This will ensure that the producer raises an exception if a majority of replicas do not receive a write."}],"partitions":1,"isControlTopic":false,"messagesPerPartition":[{"partition":0,"messages":10}]},{"keyType":"empty","valueType":"empty","totalMessages":0,"replication":1,"topicName":"device-measurement","partitions":1,"isControlTopic":false,"messagesPerPartition":[{"partition":0,"messages":0}]},{"keyType":"empty","valueType":"empty","totalMessages":0,"replication":1,"topicName":"mytopic","partitions":1,"isControlTopic":false,"messagesPerPartition":[{"partition":0,"messages":0}]},{"keyType":"empty","valueType":"empty","totalMessages":0,"replication":1,"topicName":"influx-basic2","partitions":1,"isControlTopic":false,"messagesPerPartition":[{"partition":0,"messages":0}]},{"keyType":"string","valueType":"string","totalMessages":233468,"replication":1,"topicName":"_confluent-controlcenter-0-aggregatedTopicPartitionTableWindows-FIFTEEN_SECONDS-changelog","customConfig":[{"configuration":"segment.bytes","value":"134217728","defaultValue":"1 GB","documentation":"This configuration controls the segment file size for the log. Retention and cleaning is always done a file at a time so a larger segment size means fewer files but less granular control over retention."},{"configuration":"delete.retention.ms","value":"86400000","defaultValue":"86400000","documentation":"The amount of time to retain delete tombstone markers for log compacted topics. This setting also gives a bound on the time in which a consumer must complete a read if they begin from offset 0 to ensure that they get a valid snapshot of the final stage (otherwise delete tombstones may be collected before they complete their scan). Default is 24 hours"},{"configuration":"cleanup.policy","value":"compact","defaultValue":"delete","documentation":"A string that is either \"delete\" or \"compact\". This string designates the retention policy to use on old log segments. The default policy (\"delete\") will discard old segments when their retention time or size limit has been reached. The \"compact\" setting will enable log compaction on the topic."},{"configuration":"min.insync.replicas","value":"1","defaultValue":"1","documentation":"When a producer sets acks to \"all\", min.insync.replicas specifies the minimum number of replicas that must acknowledge a write for the write to be considered successful. If this minimum cannot be met, then the producer will raise an exception (either NotEnoughReplicas or NotEnoughReplicasAfterAppend). When used together, min.insync.replicas and acks allow you to enforce greater durability guarantees. A typical scenario would be to create a topic with a replication factor of 3, set min.insync.replicas to 2, and produce with acks of \"all\". This will ensure that the producer raises an exception if a majority of replicas do not receive a write."}],"partitions":1,"isControlTopic":false,"messagesPerPartition":[{"partition":0,"messages":233468}]},{"keyType":"empty","valueType":"empty","totalMessages":0,"replication":1,"topicName":"_confluent-controlcenter-0-error-topic","customConfig":[{"configuration":"retention.ms","value":"86400000","defaultValue":"7 days","documentation":"This configuration controls the maximum time we will retain a log before we will discard old log segments to free up space if we are using the \"delete\" retention policy. This represents an SLA on how soon consumers must read their data."},{"configuration":"min.insync.replicas","value":"1","defaultValue":"1","documentation":"When a producer sets acks to \"all\", min.insync.replicas specifies the minimum number of replicas that must acknowledge a write for the write to be considered successful. If this minimum cannot be met, then the producer will raise an exception (either NotEnoughReplicas or NotEnoughReplicasAfterAppend). When used together, min.insync.replicas and acks allow you to enforce greater durability guarantees. A typical scenario would be to create a topic with a replication factor of 3, set min.insync.replicas to 2, and produce with acks of \"all\". This will ensure that the producer raises an exception if a majority of replicas do not receive a write."},{"configuration":"retention.bytes","value":"-1","defaultValue":"None","documentation":"This configuration controls the maximum size a log can grow to before we will discard old log segments to free up space if we are using the \"delete\" retention policy. By default there is no size limit only a time limit."}],"partitions":1,"isControlTopic":false,"messagesPerPartition":[{"partition":0,"messages":0}]},{"keyType":"empty","valueType":"empty","totalMessages":0,"replication":1,"topicName":"PARSEC-PAYMENTS","partitions":1,"isControlTopic":false,"messagesPerPartition":[{"partition":0,"messages":0}]},{"keyType":"empty","valueType":"empty","totalMessages":0,"replication":1,"topicName":"payments-topic","partitions":1,"isControlTopic":false,"messagesPerPartition":[{"partition":0,"messages":0}]},{"keyType":"null","valueType":"binary","totalMessages":1,"replication":1,"topicName":"test-go","partitions":1,"isControlTopic":false,"messagesPerPartition":[{"partition":0,"messages":1}]},{"keyType":"empty","valueType":"empty","totalMessages":0,"replication":1,"topicName":"coyote_connect_distributed_test-1480542744244","partitions":1,"isControlTopic":false,"messagesPerPartition":[{"partition":0,"messages":0}]},{"keyType":"string","valueType":"string","totalMessages":735,"replication":1,"topicName":"_confluent-controlcenter-0-MonitoringStream-FIFTEEN_SECONDS-changelog","customConfig":[{"configuration":"segment.bytes","value":"134217728","defaultValue":"1 GB","documentation":"This configuration controls the segment file size for the log. Retention and cleaning is always done a file at a time so a larger segment size means fewer files but less granular control over retention."},{"configuration":"delete.retention.ms","value":"86400000","defaultValue":"86400000","documentation":"The amount of time to retain delete tombstone markers for log compacted topics. This setting also gives a bound on the time in which a consumer must complete a read if they begin from offset 0 to ensure that they get a valid snapshot of the final stage (otherwise delete tombstones may be collected before they complete their scan). Default is 24 hours"},{"configuration":"cleanup.policy","value":"compact","defaultValue":"delete","documentation":"A string that is either \"delete\" or \"compact\". This string designates the retention policy to use on old log segments. The default policy (\"delete\") will discard old segments when their retention time or size limit has been reached. The \"compact\" setting will enable log compaction on the topic."},{"configuration":"min.insync.replicas","value":"1","defaultValue":"1","documentation":"When a producer sets acks to \"all\", min.insync.replicas specifies the minimum number of replicas that must acknowledge a write for the write to be considered successful. If this minimum cannot be met, then the producer will raise an exception (either NotEnoughReplicas or NotEnoughReplicasAfterAppend). When used together, min.insync.replicas and acks allow you to enforce greater durability guarantees. A typical scenario would be to create a topic with a replication factor of 3, set min.insync.replicas to 2, and produce with acks of \"all\". This will ensure that the producer raises an exception if a majority of replicas do not receive a write."}],"partitions":1,"isControlTopic":false,"messagesPerPartition":[{"partition":0,"messages":735}]},{"keyType":"empty","valueType":"empty","totalMessages":0,"replication":1,"topicName":"_confluent-controlcenter-0-group-stream-extension-rekey-changelog","customConfig":[{"configuration":"segment.bytes","value":"134217728","defaultValue":"1 GB","documentation":"This configuration controls the segment file size for the log. Retention and cleaning is always done a file at a time so a larger segment size means fewer files but less granular control over retention."},{"configuration":"delete.retention.ms","value":"86400000","defaultValue":"86400000","documentation":"The amount of time to retain delete tombstone markers for log compacted topics. This setting also gives a bound on the time in which a consumer must complete a read if they begin from offset 0 to ensure that they get a valid snapshot of the final stage (otherwise delete tombstones may be collected before they complete their scan). Default is 24 hours"},{"configuration":"cleanup.policy","value":"compact","defaultValue":"delete","documentation":"A string that is either \"delete\" or \"compact\". This string designates the retention policy to use on old log segments. The default policy (\"delete\") will discard old segments when their retention time or size limit has been reached. The \"compact\" setting will enable log compaction on the topic."},{"configuration":"min.insync.replicas","value":"1","defaultValue":"1","documentation":"When a producer sets acks to \"all\", min.insync.replicas specifies the minimum number of replicas that must acknowledge a write for the write to be considered successful. If this minimum cannot be met, then the producer will raise an exception (either NotEnoughReplicas or NotEnoughReplicasAfterAppend). When used together, min.insync.replicas and acks allow you to enforce greater durability guarantees. A typical scenario would be to create a topic with a replication factor of 3, set min.insync.replicas to 2, and produce with acks of \"all\". This will ensure that the producer raises an exception if a majority of replicas do not receive a write."}],"partitions":1,"isControlTopic":false,"messagesPerPartition":[{"partition":0,"messages":0}]},{"keyType":"empty","valueType":"empty","totalMessages":0,"replication":1,"topicName":"_confluent-controlcenter-0-group-aggregate-topic-ONE_HOUR","customConfig":[{"configuration":"retention.ms","value":"86400000","defaultValue":"7 days","documentation":"This configuration controls the maximum time we will retain a log before we will discard old log segments to free up space if we are using the \"delete\" retention policy. This represents an SLA on how soon consumers must read their data."},{"configuration":"min.insync.replicas","value":"1","defaultValue":"1","documentation":"When a producer sets acks to \"all\", min.insync.replicas specifies the minimum number of replicas that must acknowledge a write for the write to be considered successful. If this minimum cannot be met, then the producer will raise an exception (either NotEnoughReplicas or NotEnoughReplicasAfterAppend). When used together, min.insync.replicas and acks allow you to enforce greater durability guarantees. A typical scenario would be to create a topic with a replication factor of 3, set min.insync.replicas to 2, and produce with acks of \"all\". This will ensure that the producer raises an exception if a majority of replicas do not receive a write."},{"configuration":"retention.bytes","value":"-1","defaultValue":"None","documentation":"This configuration controls the maximum size a log can grow to before we will discard old log segments to free up space if we are using the \"delete\" retention policy. By default there is no size limit only a time limit."}],"partitions":1,"isControlTopic":false,"messagesPerPartition":[{"partition":0,"messages":0}]},{"keyType":"empty","valueType":"empty","totalMessages":0,"replication":1,"topicName":"coyote_test_avro","partitions":1,"isControlTopic":false,"messagesPerPartition":[{"partition":0,"messages":0}]},{"keyType":"empty","valueType":"empty","totalMessages":0,"replication":1,"topicName":"fxtest","partitions":1,"isControlTopic":false,"messagesPerPartition":[{"partition":0,"messages":0}]},{"keyType":"null","valueType":"binary","totalMessages":2,"replication":1,"topicName":"test-go-avro","partitions":1,"isControlTopic":false,"messagesPerPartition":[{"partition":0,"messages":2}]},{"keyType":"string","valueType":"string","totalMessages":37562,"replication":1,"topicName":"_confluent-controlcenter-0-aggregatedTopicPartitionTableWindows-ONE_HOUR-changelog","customConfig":[{"configuration":"segment.bytes","value":"134217728","defaultValue":"1 GB","documentation":"This configuration controls the segment file size for the log. Retention and cleaning is always done a file at a time so a larger segment size means fewer files but less granular control over retention."},{"configuration":"delete.retention.ms","value":"86400000","defaultValue":"86400000","documentation":"The amount of time to retain delete tombstone markers for log compacted topics. This setting also gives a bound on the time in which a consumer must complete a read if they begin from offset 0 to ensure that they get a valid snapshot of the final stage (otherwise delete tombstones may be collected before they complete their scan). Default is 24 hours"},{"configuration":"cleanup.policy","value":"compact","defaultValue":"delete","documentation":"A string that is either \"delete\" or \"compact\". This string designates the retention policy to use on old log segments. The default policy (\"delete\") will discard old segments when their retention time or size limit has been reached. The \"compact\" setting will enable log compaction on the topic."},{"configuration":"min.insync.replicas","value":"1","defaultValue":"1","documentation":"When a producer sets acks to \"all\", min.insync.replicas specifies the minimum number of replicas that must acknowledge a write for the write to be considered successful. If this minimum cannot be met, then the producer will raise an exception (either NotEnoughReplicas or NotEnoughReplicasAfterAppend). When used together, min.insync.replicas and acks allow you to enforce greater durability guarantees. A typical scenario would be to create a topic with a replication factor of 3, set min.insync.replicas to 2, and produce with acks of \"all\". This will ensure that the producer raises an exception if a majority of replicas do not receive a write."}],"partitions":1,"isControlTopic":false,"messagesPerPartition":[{"partition":0,"messages":37562}]},{"keyType":"","valueType":"","totalMessages":7693,"replication":1,"topicName":"_confluent-controlcenter-0-aggregate-topic-partition","customConfig":[{"configuration":"retention.ms","value":"86400000","defaultValue":"7 days","documentation":"This configuration controls the maximum time we will retain a log before we will discard old log segments to free up space if we are using the \"delete\" retention policy. This represents an SLA on how soon consumers must read their data."},{"configuration":"min.insync.replicas","value":"1","defaultValue":"1","documentation":"When a producer sets acks to \"all\", min.insync.replicas specifies the minimum number of replicas that must acknowledge a write for the write to be considered successful. If this minimum cannot be met, then the producer will raise an exception (either NotEnoughReplicas or NotEnoughReplicasAfterAppend). When used together, min.insync.replicas and acks allow you to enforce greater durability guarantees. A typical scenario would be to create a topic with a replication factor of 3, set min.insync.replicas to 2, and produce with acks of \"all\". This will ensure that the producer raises an exception if a majority of replicas do not receive a write."},{"configuration":"retention.bytes","value":"-1","defaultValue":"None","documentation":"This configuration controls the maximum size a log can grow to before we will discard old log segments to free up space if we are using the \"delete\" retention policy. By default there is no size limit only a time limit."}],"partitions":1,"isControlTopic":false,"messagesPerPartition":[{"partition":0,"messages":7693}]},{"keyType":"empty","valueType":"empty","totalMessages":0,"replication":1,"topicName":"_confluent-controlcenter-0-MonitoringMessageAggregatorWindows-ONE_WEEK-changelog","customConfig":[{"configuration":"segment.bytes","value":"134217728","defaultValue":"1 GB","documentation":"This configuration controls the segment file size for the log. Retention and cleaning is always done a file at a time so a larger segment size means fewer files but less granular control over retention."},{"configuration":"delete.retention.ms","value":"86400000","defaultValue":"86400000","documentation":"The amount of time to retain delete tombstone markers for log compacted topics. This setting also gives a bound on the time in which a consumer must complete a read if they begin from offset 0 to ensure that they get a valid snapshot of the final stage (otherwise delete tombstones may be collected before they complete their scan). Default is 24 hours"},{"configuration":"cleanup.policy","value":"compact","defaultValue":"delete","documentation":"A string that is either \"delete\" or \"compact\". This string designates the retention policy to use on old log segments. The default policy (\"delete\") will discard old segments when their retention time or size limit has been reached. The \"compact\" setting will enable log compaction on the topic."},{"configuration":"min.insync.replicas","value":"1","defaultValue":"1","documentation":"When a producer sets acks to \"all\", min.insync.replicas specifies the minimum number of replicas that must acknowledge a write for the write to be considered successful. If this minimum cannot be met, then the producer will raise an exception (either NotEnoughReplicas or NotEnoughReplicasAfterAppend). When used together, min.insync.replicas and acks allow you to enforce greater durability guarantees. A typical scenario would be to create a topic with a replication factor of 3, set min.insync.replicas to 2, and produce with acks of \"all\". This will ensure that the producer raises an exception if a majority of replicas do not receive a write."}],"partitions":1,"isControlTopic":false,"messagesPerPartition":[{"partition":0,"messages":0}]},{"keyType":"","valueType":"","totalMessages":499734,"replication":1,"topicName":"blockchains","partitions":1,"isControlTopic":false,"messagesPerPartition":[{"partition":0,"messages":499734}]},{"keyType":"","valueType":"avro","totalMessages":48468,"replication":1,"topicName":"yahoo-stocks","partitions":1,"isControlTopic":false,"messagesPerPartition":[{"partition":0,"messages":48468}]},{"keyType":"empty","valueType":"empty","totalMessages":0,"replication":1,"topicName":"coyote_test_binary","partitions":1,"isControlTopic":false,"messagesPerPartition":[{"partition":0,"messages":0}]},{"keyType":"","valueType":"","totalMessages":82921,"replication":1,"topicName":"connect-offsets","partitions":1,"isControlTopic":true,"messagesPerPartition":[{"partition":0,"messages":82921}]},{"keyType":"empty","valueType":"empty","totalMessages":0,"replication":1,"topicName":"_confluent-controlcenter-0-group-stream-extension-rekey","customConfig":[{"configuration":"retention.ms","value":"86400000","defaultValue":"7 days","documentation":"This configuration controls the maximum time we will retain a log before we will discard old log segments to free up space if we are using the \"delete\" retention policy. This represents an SLA on how soon consumers must read their data."},{"configuration":"min.insync.replicas","value":"1","defaultValue":"1","documentation":"When a producer sets acks to \"all\", min.insync.replicas specifies the minimum number of replicas that must acknowledge a write for the write to be considered successful. If this minimum cannot be met, then the producer will raise an exception (either NotEnoughReplicas or NotEnoughReplicasAfterAppend). When used together, min.insync.replicas and acks allow you to enforce greater durability guarantees. A typical scenario would be to create a topic with a replication factor of 3, set min.insync.replicas to 2, and produce with acks of \"all\". This will ensure that the producer raises an exception if a majority of replicas do not receive a write."},{"configuration":"retention.bytes","value":"-1","defaultValue":"None","documentation":"This configuration controls the maximum size a log can grow to before we will discard old log segments to free up space if we are using the \"delete\" retention policy. By default there is no size limit only a time limit."}],"partitions":1,"isControlTopic":false,"messagesPerPartition":[{"partition":0,"messages":0}]},{"keyType":"empty","valueType":"empty","totalMessages":0,"replication":1,"topicName":"_confluent-controlcenter-0-MonitoringMessageAggregatorWindows-FIFTEEN_SECONDS-changelog","customConfig":[{"configuration":"segment.bytes","value":"134217728","defaultValue":"1 GB","documentation":"This configuration controls the segment file size for the log. Retention and cleaning is always done a file at a time so a larger segment size means fewer files but less granular control over retention."},{"configuration":"delete.retention.ms","value":"86400000","defaultValue":"86400000","documentation":"The amount of time to retain delete tombstone markers for log compacted topics. This setting also gives a bound on the time in which a consumer must complete a read if they begin from offset 0 to ensure that they get a valid snapshot of the final stage (otherwise delete tombstones may be collected before they complete their scan). Default is 24 hours"},{"configuration":"cleanup.policy","value":"compact","defaultValue":"delete","documentation":"A string that is either \"delete\" or \"compact\". This string designates the retention policy to use on old log segments. The default policy (\"delete\") will discard old segments when their retention time or size limit has been reached. The \"compact\" setting will enable log compaction on the topic."},{"configuration":"min.insync.replicas","value":"1","defaultValue":"1","documentation":"When a producer sets acks to \"all\", min.insync.replicas specifies the minimum number of replicas that must acknowledge a write for the write to be considered successful. If this minimum cannot be met, then the producer will raise an exception (either NotEnoughReplicas or NotEnoughReplicasAfterAppend). When used together, min.insync.replicas and acks allow you to enforce greater durability guarantees. A typical scenario would be to create a topic with a replication factor of 3, set min.insync.replicas to 2, and produce with acks of \"all\". This will ensure that the producer raises an exception if a majority of replicas do not receive a write."}],"partitions":1,"isControlTopic":false,"messagesPerPartition":[{"partition":0,"messages":0}]},{"keyType":"empty","valueType":"empty","totalMessages":0,"replication":1,"topicName":"iot-example","partitions":1,"isControlTopic":false,"messagesPerPartition":[{"partition":0,"messages":0}]},{"keyType":"empty","valueType":"empty","totalMessages":0,"replication":1,"topicName":"_confluent-controlcenter-0-MonitoringMessageAggregatorWindows-ONE_HOUR-changelog","customConfig":[{"configuration":"segment.bytes","value":"134217728","defaultValue":"1 GB","documentation":"This configuration controls the segment file size for the log. Retention and cleaning is always done a file at a time so a larger segment size means fewer files but less granular control over retention."},{"configuration":"delete.retention.ms","value":"86400000","defaultValue":"86400000","documentation":"The amount of time to retain delete tombstone markers for log compacted topics. This setting also gives a bound on the time in which a consumer must complete a read if they begin from offset 0 to ensure that they get a valid snapshot of the final stage (otherwise delete tombstones may be collected before they complete their scan). Default is 24 hours"},{"configuration":"cleanup.policy","value":"compact","defaultValue":"delete","documentation":"A string that is either \"delete\" or \"compact\". This string designates the retention policy to use on old log segments. The default policy (\"delete\") will discard old segments when their retention time or size limit has been reached. The \"compact\" setting will enable log compaction on the topic."},{"configuration":"min.insync.replicas","value":"1","defaultValue":"1","documentation":"When a producer sets acks to \"all\", min.insync.replicas specifies the minimum number of replicas that must acknowledge a write for the write to be considered successful. If this minimum cannot be met, then the producer will raise an exception (either NotEnoughReplicas or NotEnoughReplicasAfterAppend). When used together, min.insync.replicas and acks allow you to enforce greater durability guarantees. A typical scenario would be to create a topic with a replication factor of 3, set min.insync.replicas to 2, and produce with acks of \"all\". This will ensure that the producer raises an exception if a majority of replicas do not receive a write."}],"partitions":1,"isControlTopic":false,"messagesPerPartition":[{"partition":0,"messages":0}]},{"keyType":"empty","valueType":"empty","totalMessages":0,"replication":1,"topicName":"_confluent-controlcenter-0-monitoring-aggregate-rekey","customConfig":[{"configuration":"retention.ms","value":"86400000","defaultValue":"7 days","documentation":"This configuration controls the maximum time we will retain a log before we will discard old log segments to free up space if we are using the \"delete\" retention policy. This represents an SLA on how soon consumers must read their data."},{"configuration":"min.insync.replicas","value":"1","defaultValue":"1","documentation":"When a producer sets acks to \"all\", min.insync.replicas specifies the minimum number of replicas that must acknowledge a write for the write to be considered successful. If this minimum cannot be met, then the producer will raise an exception (either NotEnoughReplicas or NotEnoughReplicasAfterAppend). When used together, min.insync.replicas and acks allow you to enforce greater durability guarantees. A typical scenario would be to create a topic with a replication factor of 3, set min.insync.replicas to 2, and produce with acks of \"all\". This will ensure that the producer raises an exception if a majority of replicas do not receive a write."},{"configuration":"retention.bytes","value":"-1","defaultValue":"None","documentation":"This configuration controls the maximum size a log can grow to before we will discard old log segments to free up space if we are using the \"delete\" retention policy. By default there is no size limit only a time limit."}],"partitions":1,"isControlTopic":false,"messagesPerPartition":[{"partition":0,"messages":0}]},{"keyType":"empty","valueType":"empty","totalMessages":0,"replication":1,"topicName":"christina","partitions":1,"isControlTopic":false,"messagesPerPartition":[{"partition":0,"messages":0}]},{"keyType":"","valueType":"","totalMessages":2167306,"replication":1,"topicName":"_confluent-controlcenter-0-aggregate-topic-partition-changelog","customConfig":[{"configuration":"segment.bytes","value":"134217728","defaultValue":"1 GB","documentation":"This configuration controls the segment file size for the log. Retention and cleaning is always done a file at a time so a larger segment size means fewer files but less granular control over retention."},{"configuration":"delete.retention.ms","value":"86400000","defaultValue":"86400000","documentation":"The amount of time to retain delete tombstone markers for log compacted topics. This setting also gives a bound on the time in which a consumer must complete a read if they begin from offset 0 to ensure that they get a valid snapshot of the final stage (otherwise delete tombstones may be collected before they complete their scan). Default is 24 hours"},{"configuration":"cleanup.policy","value":"compact","defaultValue":"delete","documentation":"A string that is either \"delete\" or \"compact\". This string designates the retention policy to use on old log segments. The default policy (\"delete\") will discard old segments when their retention time or size limit has been reached. The \"compact\" setting will enable log compaction on the topic."},{"configuration":"min.insync.replicas","value":"1","defaultValue":"1","documentation":"When a producer sets acks to \"all\", min.insync.replicas specifies the minimum number of replicas that must acknowledge a write for the write to be considered successful. If this minimum cannot be met, then the producer will raise an exception (either NotEnoughReplicas or NotEnoughReplicasAfterAppend). When used together, min.insync.replicas and acks allow you to enforce greater durability guarantees. A typical scenario would be to create a topic with a replication factor of 3, set min.insync.replicas to 2, and produce with acks of \"all\". This will ensure that the producer raises an exception if a majority of replicas do not receive a write."}],"partitions":1,"isControlTopic":false,"messagesPerPartition":[{"partition":0,"messages":2167306}]},{"keyType":"empty","valueType":"empty","totalMessages":0,"replication":1,"topicName":"device-measurements-topic3","partitions":1,"isControlTopic":false,"messagesPerPartition":[{"partition":0,"messages":0}]},{"keyType":"","valueType":"","totalMessages":56237,"replication":1,"topicName":"_confluent-controlcenter-0-monitoring-message-rekey","customConfig":[{"configuration":"retention.ms","value":"86400000","defaultValue":"7 days","documentation":"This configuration controls the maximum time we will retain a log before we will discard old log segments to free up space if we are using the \"delete\" retention policy. This represents an SLA on how soon consumers must read their data."},{"configuration":"min.insync.replicas","value":"1","defaultValue":"1","documentation":"When a producer sets acks to \"all\", min.insync.replicas specifies the minimum number of replicas that must acknowledge a write for the write to be considered successful. If this minimum cannot be met, then the producer will raise an exception (either NotEnoughReplicas or NotEnoughReplicasAfterAppend). When used together, min.insync.replicas and acks allow you to enforce greater durability guarantees. A typical scenario would be to create a topic with a replication factor of 3, set min.insync.replicas to 2, and produce with acks of \"all\". This will ensure that the producer raises an exception if a majority of replicas do not receive a write."},{"configuration":"retention.bytes","value":"-1","defaultValue":"None","documentation":"This configuration controls the maximum size a log can grow to before we will discard old log segments to free up space if we are using the \"delete\" retention policy. By default there is no size limit only a time limit."}],"partitions":1,"isControlTopic":false,"messagesPerPartition":[{"partition":0,"messages":56237}]},{"keyType":"string","valueType":"string","totalMessages":15,"replication":1,"topicName":"_confluent-controlcenter-0-Group-ONE_WEEK-changelog","customConfig":[{"configuration":"segment.bytes","value":"134217728","defaultValue":"1 GB","documentation":"This configuration controls the segment file size for the log. Retention and cleaning is always done a file at a time so a larger segment size means fewer files but less granular control over retention."},{"configuration":"delete.retention.ms","value":"86400000","defaultValue":"86400000","documentation":"The amount of time to retain delete tombstone markers for log compacted topics. This setting also gives a bound on the time in which a consumer must complete a read if they begin from offset 0 to ensure that they get a valid snapshot of the final stage (otherwise delete tombstones may be collected before they complete their scan). Default is 24 hours"},{"configuration":"cleanup.policy","value":"compact","defaultValue":"delete","documentation":"A string that is either \"delete\" or \"compact\". This string designates the retention policy to use on old log segments. The default policy (\"delete\") will discard old segments when their retention time or size limit has been reached. The \"compact\" setting will enable log compaction on the topic."},{"configuration":"min.insync.replicas","value":"1","defaultValue":"1","documentation":"When a producer sets acks to \"all\", min.insync.replicas specifies the minimum number of replicas that must acknowledge a write for the write to be considered successful. If this minimum cannot be met, then the producer will raise an exception (either NotEnoughReplicas or NotEnoughReplicasAfterAppend). When used together, min.insync.replicas and acks allow you to enforce greater durability guarantees. A typical scenario would be to create a topic with a replication factor of 3, set min.insync.replicas to 2, and produce with acks of \"all\". This will ensure that the producer raises an exception if a majority of replicas do not receive a write."}],"partitions":1,"isControlTopic":false,"messagesPerPartition":[{"partition":0,"messages":15}]},{"keyType":"string","valueType":"json","totalMessages":851,"replication":1,"topicName":"connect-status","partitions":1,"isControlTopic":true,"messagesPerPartition":[{"partition":0,"messages":851}]},{"keyType":"string","valueType":"string","totalMessages":10,"replication":1,"topicName":"_confluent-controlcenter-0-Group-ONE_HOUR-changelog","customConfig":[{"configuration":"segment.bytes","value":"134217728","defaultValue":"1 GB","documentation":"This configuration controls the segment file size for the log. Retention and cleaning is always done a file at a time so a larger segment size means fewer files but less granular control over retention."},{"configuration":"delete.retention.ms","value":"86400000","defaultValue":"86400000","documentation":"The amount of time to retain delete tombstone markers for log compacted topics. This setting also gives a bound on the time in which a consumer must complete a read if they begin from offset 0 to ensure that they get a valid snapshot of the final stage (otherwise delete tombstones may be collected before they complete their scan). Default is 24 hours"},{"configuration":"cleanup.policy","value":"compact","defaultValue":"delete","documentation":"A string that is either \"delete\" or \"compact\". This string designates the retention policy to use on old log segments. The default policy (\"delete\") will discard old segments when their retention time or size limit has been reached. The \"compact\" setting will enable log compaction on the topic."},{"configuration":"min.insync.replicas","value":"1","defaultValue":"1","documentation":"When a producer sets acks to \"all\", min.insync.replicas specifies the minimum number of replicas that must acknowledge a write for the write to be considered successful. If this minimum cannot be met, then the producer will raise an exception (either NotEnoughReplicas or NotEnoughReplicasAfterAppend). When used together, min.insync.replicas and acks allow you to enforce greater durability guarantees. A typical scenario would be to create a topic with a replication factor of 3, set min.insync.replicas to 2, and produce with acks of \"all\". This will ensure that the producer raises an exception if a majority of replicas do not receive a write."}],"partitions":1,"isControlTopic":false,"messagesPerPartition":[{"partition":0,"messages":10}]},{"keyType":"empty","valueType":"empty","totalMessages":0,"replication":1,"topicName":"_confluent-controlcenter-0-group-aggregate-topic-ONE_HOUR-changelog","customConfig":[{"configuration":"segment.bytes","value":"134217728","defaultValue":"1 GB","documentation":"This configuration controls the segment file size for the log. Retention and cleaning is always done a file at a time so a larger segment size means fewer files but less granular control over retention."},{"configuration":"delete.retention.ms","value":"86400000","defaultValue":"86400000","documentation":"The amount of time to retain delete tombstone markers for log compacted topics. This setting also gives a bound on the time in which a consumer must complete a read if they begin from offset 0 to ensure that they get a valid snapshot of the final stage (otherwise delete tombstones may be collected before they complete their scan). Default is 24 hours"},{"configuration":"cleanup.policy","value":"compact","defaultValue":"delete","documentation":"A string that is either \"delete\" or \"compact\". This string designates the retention policy to use on old log segments. The default policy (\"delete\") will discard old segments when their retention time or size limit has been reached. The \"compact\" setting will enable log compaction on the topic."},{"configuration":"min.insync.replicas","value":"1","defaultValue":"1","documentation":"When a producer sets acks to \"all\", min.insync.replicas specifies the minimum number of replicas that must acknowledge a write for the write to be considered successful. If this minimum cannot be met, then the producer will raise an exception (either NotEnoughReplicas or NotEnoughReplicasAfterAppend). When used together, min.insync.replicas and acks allow you to enforce greater durability guarantees. A typical scenario would be to create a topic with a replication factor of 3, set min.insync.replicas to 2, and produce with acks of \"all\". This will ensure that the producer raises an exception if a majority of replicas do not receive a write."}],"partitions":1,"isControlTopic":false,"messagesPerPartition":[{"partition":0,"messages":0}]},{"keyType":"empty","valueType":"empty","totalMessages":0,"replication":1,"topicName":"device-temperature","partitions":1,"isControlTopic":false,"messagesPerPartition":[{"partition":0,"messages":0}]},{"keyType":"string","valueType":"null","totalMessages":204225,"replication":1,"topicName":"_confluent-controlcenter-0-MonitoringVerifierStore-changelog","customConfig":[{"configuration":"segment.bytes","value":"134217728","defaultValue":"1 GB","documentation":"This configuration controls the segment file size for the log. Retention and cleaning is always done a file at a time so a larger segment size means fewer files but less granular control over retention."},{"configuration":"delete.retention.ms","value":"86400000","defaultValue":"86400000","documentation":"The amount of time to retain delete tombstone markers for log compacted topics. This setting also gives a bound on the time in which a consumer must complete a read if they begin from offset 0 to ensure that they get a valid snapshot of the final stage (otherwise delete tombstones may be collected before they complete their scan). Default is 24 hours"},{"configuration":"cleanup.policy","value":"compact","defaultValue":"delete","documentation":"A string that is either \"delete\" or \"compact\". This string designates the retention policy to use on old log segments. The default policy (\"delete\") will discard old segments when their retention time or size limit has been reached. The \"compact\" setting will enable log compaction on the topic."},{"configuration":"min.insync.replicas","value":"1","defaultValue":"1","documentation":"When a producer sets acks to \"all\", min.insync.replicas specifies the minimum number of replicas that must acknowledge a write for the write to be considered successful. If this minimum cannot be met, then the producer will raise an exception (either NotEnoughReplicas or NotEnoughReplicasAfterAppend). When used together, min.insync.replicas and acks allow you to enforce greater durability guarantees. A typical scenario would be to create a topic with a replication factor of 3, set min.insync.replicas to 2, and produce with acks of \"all\". This will ensure that the producer raises an exception if a majority of replicas do not receive a write."}],"partitions":1,"isControlTopic":false,"messagesPerPartition":[{"partition":0,"messages":204225}]},{"keyType":"json","valueType":"json","totalMessages":153,"replication":1,"topicName":"_schemas","customConfig":[{"configuration":"cleanup.policy","value":"compact","defaultValue":"delete","documentation":"A string that is either \"delete\" or \"compact\". This string designates the retention policy to use on old log segments. The default policy (\"delete\") will discard old segments when their retention time or size limit has been reached. The \"compact\" setting will enable log compaction on the topic."}],"partitions":1,"isControlTopic":true,"messagesPerPartition":[{"partition":0,"messages":153}]},{"keyType":"null","valueType":"null","totalMessages":10,"replication":1,"topicName":"test-go-devme3","partitions":1,"isControlTopic":false,"messagesPerPartition":[{"partition":0,"messages":10}]},{"keyType":"null","valueType":"binary","totalMessages":3,"replication":1,"topicName":"test-go-devme4","partitions":1,"isControlTopic":false,"messagesPerPartition":[{"partition":0,"messages":3}]},{"keyType":"empty","valueType":"empty","totalMessages":0,"replication":1,"topicName":"coyote_test_json","partitions":1,"isControlTopic":false,"messagesPerPartition":[{"partition":0,"messages":0}]},{"keyType":"empty","valueType":"empty","totalMessages":0,"replication":1,"topicName":"_confluent-controlcenter-0-group-aggregate-topic-FIFTEEN_SECONDS","customConfig":[{"configuration":"retention.ms","value":"86400000","defaultValue":"7 days","documentation":"This configuration controls the maximum time we will retain a log before we will discard old log segments to free up space if we are using the \"delete\" retention policy. This represents an SLA on how soon consumers must read their data."},{"configuration":"min.insync.replicas","value":"1","defaultValue":"1","documentation":"When a producer sets acks to \"all\", min.insync.replicas specifies the minimum number of replicas that must acknowledge a write for the write to be considered successful. If this minimum cannot be met, then the producer will raise an exception (either NotEnoughReplicas or NotEnoughReplicasAfterAppend). When used together, min.insync.replicas and acks allow you to enforce greater durability guarantees. A typical scenario would be to create a topic with a replication factor of 3, set min.insync.replicas to 2, and produce with acks of \"all\". This will ensure that the producer raises an exception if a majority of replicas do not receive a write."},{"configuration":"retention.bytes","value":"-1","defaultValue":"None","documentation":"This configuration controls the maximum size a log can grow to before we will discard old log segments to free up space if we are using the \"delete\" retention policy. By default there is no size limit only a time limit."}],"partitions":1,"isControlTopic":false,"messagesPerPartition":[{"partition":0,"messages":0}]},{"keyType":"empty","valueType":"empty","totalMessages":0,"replication":1,"topicName":"hazelcast-dev","partitions":1,"isControlTopic":false,"messagesPerPartition":[{"partition":0,"messages":0}]},{"keyType":"string","valueType":"string","totalMessages":735,"replication":1,"topicName":"_confluent-controlcenter-0-monitoring-aggregate-rekey-changelog","customConfig":[{"configuration":"segment.bytes","value":"134217728","defaultValue":"1 GB","documentation":"This configuration controls the segment file size for the log. Retention and cleaning is always done a file at a time so a larger segment size means fewer files but less granular control over retention."},{"configuration":"delete.retention.ms","value":"86400000","defaultValue":"86400000","documentation":"The amount of time to retain delete tombstone markers for log compacted topics. This setting also gives a bound on the time in which a consumer must complete a read if they begin from offset 0 to ensure that they get a valid snapshot of the final stage (otherwise delete tombstones may be collected before they complete their scan). Default is 24 hours"},{"configuration":"cleanup.policy","value":"compact","defaultValue":"delete","documentation":"A string that is either \"delete\" or \"compact\". This string designates the retention policy to use on old log segments. The default policy (\"delete\") will discard old segments when their retention time or size limit has been reached. The \"compact\" setting will enable log compaction on the topic."},{"configuration":"min.insync.replicas","value":"1","defaultValue":"1","documentation":"When a producer sets acks to \"all\", min.insync.replicas specifies the minimum number of replicas that must acknowledge a write for the write to be considered successful. If this minimum cannot be met, then the producer will raise an exception (either NotEnoughReplicas or NotEnoughReplicasAfterAppend). When used together, min.insync.replicas and acks allow you to enforce greater durability guarantees. A typical scenario would be to create a topic with a replication factor of 3, set min.insync.replicas to 2, and produce with acks of \"all\". This will ensure that the producer raises an exception if a majority of replicas do not receive a write."}],"partitions":1,"isControlTopic":false,"messagesPerPartition":[{"partition":0,"messages":735}]},{"keyType":"empty","valueType":"empty","totalMessages":0,"replication":1,"topicName":"newsletter-tweets","partitions":1,"isControlTopic":false,"messagesPerPartition":[{"partition":0,"messages":0}]},{"keyType":"","valueType":"avro","totalMessages":12063301,"replication":1,"topicName":"kafka-connect-logs","partitions":1,"isControlTopic":false,"messagesPerPartition":[{"partition":0,"messages":12063301}]},{"keyType":"empty","valueType":"empty","totalMessages":0,"replication":1,"topicName":"_confluent-controlcenter-0-group-aggregate-topic-FIFTEEN_SECONDS-changelog","customConfig":[{"configuration":"segment.bytes","value":"134217728","defaultValue":"1 GB","documentation":"This configuration controls the segment file size for the log. Retention and cleaning is always done a file at a time so a larger segment size means fewer files but less granular control over retention."},{"configuration":"delete.retention.ms","value":"86400000","defaultValue":"86400000","documentation":"The amount of time to retain delete tombstone markers for log compacted topics. This setting also gives a bound on the time in which a consumer must complete a read if they begin from offset 0 to ensure that they get a valid snapshot of the final stage (otherwise delete tombstones may be collected before they complete their scan). Default is 24 hours"},{"configuration":"cleanup.policy","value":"compact","defaultValue":"delete","documentation":"A string that is either \"delete\" or \"compact\". This string designates the retention policy to use on old log segments. The default policy (\"delete\") will discard old segments when their retention time or size limit has been reached. The \"compact\" setting will enable log compaction on the topic."},{"configuration":"min.insync.replicas","value":"1","defaultValue":"1","documentation":"When a producer sets acks to \"all\", min.insync.replicas specifies the minimum number of replicas that must acknowledge a write for the write to be considered successful. If this minimum cannot be met, then the producer will raise an exception (either NotEnoughReplicas or NotEnoughReplicasAfterAppend). When used together, min.insync.replicas and acks allow you to enforce greater durability guarantees. A typical scenario would be to create a topic with a replication factor of 3, set min.insync.replicas to 2, and produce with acks of \"all\". This will ensure that the producer raises an exception if a majority of replicas do not receive a write."}],"partitions":1,"isControlTopic":false,"messagesPerPartition":[{"partition":0,"messages":0}]},{"keyType":"empty","valueType":"empty","totalMessages":0,"replication":1,"topicName":"_confluent-controlcenter-0-group-aggregate-topic-ONE_WEEK-changelog","customConfig":[{"configuration":"segment.bytes","value":"134217728","defaultValue":"1 GB","documentation":"This configuration controls the segment file size for the log. Retention and cleaning is always done a file at a time so a larger segment size means fewer files but less granular control over retention."},{"configuration":"delete.retention.ms","value":"86400000","defaultValue":"86400000","documentation":"The amount of time to retain delete tombstone markers for log compacted topics. This setting also gives a bound on the time in which a consumer must complete a read if they begin from offset 0 to ensure that they get a valid snapshot of the final stage (otherwise delete tombstones may be collected before they complete their scan). Default is 24 hours"},{"configuration":"cleanup.policy","value":"compact","defaultValue":"delete","documentation":"A string that is either \"delete\" or \"compact\". This string designates the retention policy to use on old log segments. The default policy (\"delete\") will discard old segments when their retention time or size limit has been reached. The \"compact\" setting will enable log compaction on the topic."},{"configuration":"min.insync.replicas","value":"1","defaultValue":"1","documentation":"When a producer sets acks to \"all\", min.insync.replicas specifies the minimum number of replicas that must acknowledge a write for the write to be considered successful. If this minimum cannot be met, then the producer will raise an exception (either NotEnoughReplicas or NotEnoughReplicasAfterAppend). When used together, min.insync.replicas and acks allow you to enforce greater durability guarantees. A typical scenario would be to create a topic with a replication factor of 3, set min.insync.replicas to 2, and produce with acks of \"all\". This will ensure that the producer raises an exception if a majority of replicas do not receive a write."}],"partitions":1,"isControlTopic":false,"messagesPerPartition":[{"partition":0,"messages":0}]},{"keyType":"","valueType":"","totalMessages":246425,"replication":1,"topicName":"_confluent-monitoring","customConfig":[{"configuration":"retention.ms","value":"259200000","defaultValue":"7 days","documentation":"This configuration controls the maximum time we will retain a log before we will discard old log segments to free up space if we are using the \"delete\" retention policy. This represents an SLA on how soon consumers must read their data."},{"configuration":"min.insync.replicas","value":"1","defaultValue":"1","documentation":"When a producer sets acks to \"all\", min.insync.replicas specifies the minimum number of replicas that must acknowledge a write for the write to be considered successful. If this minimum cannot be met, then the producer will raise an exception (either NotEnoughReplicas or NotEnoughReplicasAfterAppend). When used together, min.insync.replicas and acks allow you to enforce greater durability guarantees. A typical scenario would be to create a topic with a replication factor of 3, set min.insync.replicas to 2, and produce with acks of \"all\". This will ensure that the producer raises an exception if a majority of replicas do not receive a write."},{"configuration":"retention.bytes","value":"-1","defaultValue":"None","documentation":"This configuration controls the maximum size a log can grow to before we will discard old log segments to free up space if we are using the \"delete\" retention policy. By default there is no size limit only a time limit."}],"partitions":1,"isControlTopic":true,"messagesPerPartition":[{"partition":0,"messages":246425}]},{"keyType":"empty","valueType":"empty","totalMessages":0,"replication":1,"topicName":"fstab","partitions":1,"isControlTopic":false,"messagesPerPartition":[{"partition":0,"messages":0}]},{"keyType":"string","valueType":"string","totalMessages":34139,"replication":1,"topicName":"_confluent-controlcenter-0-aggregatedTopicPartitionTableWindows-ONE_WEEK-changelog","customConfig":[{"configuration":"segment.bytes","value":"134217728","defaultValue":"1 GB","documentation":"This configuration controls the segment file size for the log. Retention and cleaning is always done a file at a time so a larger segment size means fewer files but less granular control over retention."},{"configuration":"delete.retention.ms","value":"86400000","defaultValue":"86400000","documentation":"The amount of time to retain delete tombstone markers for log compacted topics. This setting also gives a bound on the time in which a consumer must complete a read if they begin from offset 0 to ensure that they get a valid snapshot of the final stage (otherwise delete tombstones may be collected before they complete their scan). Default is 24 hours"},{"configuration":"cleanup.policy","value":"compact","defaultValue":"delete","documentation":"A string that is either \"delete\" or \"compact\". This string designates the retention policy to use on old log segments. The default policy (\"delete\") will discard old segments when their retention time or size limit has been reached. The \"compact\" setting will enable log compaction on the topic."},{"configuration":"min.insync.replicas","value":"1","defaultValue":"1","documentation":"When a producer sets acks to \"all\", min.insync.replicas specifies the minimum number of replicas that must acknowledge a write for the write to be considered successful. If this minimum cannot be met, then the producer will raise an exception (either NotEnoughReplicas or NotEnoughReplicasAfterAppend). When used together, min.insync.replicas and acks allow you to enforce greater durability guarantees. A typical scenario would be to create a topic with a replication factor of 3, set min.insync.replicas to 2, and produce with acks of \"all\". This will ensure that the producer raises an exception if a majority of replicas do not receive a write."}],"partitions":1,"isControlTopic":false,"messagesPerPartition":[{"partition":0,"messages":34139}]},{"keyType":"","valueType":"","totalMessages":727916,"replication":1,"topicName":"__consumer_offsets","customConfig":[{"configuration":"segment.bytes","value":"104857600","defaultValue":"1 GB","documentation":"This configuration controls the segment file size for the log. Retention and cleaning is always done a file at a time so a larger segment size means fewer files but less granular control over retention."},{"configuration":"compression.type","value":"producer"},{"configuration":"cleanup.policy","value":"compact","defaultValue":"delete","documentation":"A string that is either \"delete\" or \"compact\". This string designates the retention policy to use on old log segments. The default policy (\"delete\") will discard old segments when their retention time or size limit has been reached. The \"compact\" setting will enable log compaction on the topic."}],"partitions":50,"isControlTopic":true,"messagesPerPartition":[{"partition":0,"messages":6},{"partition":5,"messages":6},{"partition":10,"messages":0},{"partition":42,"messages":2},{"partition":24,"messages":0},{"partition":37,"messages":0},{"partition":25,"messages":0},{"partition":14,"messages":0},{"partition":20,"messages":0},{"partition":46,"messages":0},{"partition":29,"messages":0},{"partition":1,"messages":0},{"partition":6,"messages":501845},{"partition":28,"messages":0},{"partition":38,"messages":0},{"partition":21,"messages":4},{"partition":33,"messages":0},{"partition":9,"messages":0},{"partition":13,"messages":244},{"partition":41,"messages":0},{"partition":2,"messages":0},{"partition":32,"messages":0},{"partition":34,"messages":0},{"partition":45,"messages":0},{"partition":17,"messages":0},{"partition":22,"messages":2},{"partition":44,"messages":6},{"partition":27,"messages":0},{"partition":12,"messages":31},{"partition":49,"messages":90304},{"partition":7,"messages":0},{"partition":39,"messages":0},{"partition":3,"messages":0},{"partition":35,"messages":0},{"partition":48,"messages":4},{"partition":18,"messages":21},{"partition":16,"messages":258},{"partition":31,"messages":0},{"partition":11,"messages":0},{"partition":43,"messages":0},{"partition":40,"messages":135183},{"partition":26,"messages":0},{"partition":23,"messages":0},{"partition":8,"messages":0},{"partition":36,"messages":0},{"partition":30,"messages":0},{"partition":19,"messages":0},{"partition":4,"messages":0},{"partition":47,"messages":0},{"partition":15,"messages":0}]},{"keyType":"null","valueType":"binary","totalMessages":59,"replication":1,"topicName":"__confluent.support.metrics","customConfig":[{"configuration":"retention.ms","value":"31536000000","defaultValue":"7 days","documentation":"This configuration controls the maximum time we will retain a log before we will discard old log segments to free up space if we are using the \"delete\" retention policy. This represents an SLA on how soon consumers must read their data."}],"partitions":1,"isControlTopic":false,"messagesPerPartition":[{"partition":0,"messages":59}]}]
return data;
}

return {
getListInfo: function () {
      return getListInfo();
    },
}

});